---
title: "Unpacking the Invisible: Exploring the Mental Health Challenges of Living Through a Global Pandemic"
author: " Carlos van der Ley, Christine Kwon, Connor Bates, Leonardo Gonzalez"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
bibliography: references.bib
link-citations: true
---

## Introduction

Mental health represents a critical aspect of an individual's overall well being as well as am important branch of Cognitive Science. Understanding not only a single individual's mental health, but also community's discussions and perceptions of mental health are essential to providing people with the help and support that they need. One online platform where community members come together to discuss mental and addiction topics is the online forum Reddit. Beginning in late 2018, data was collected from the platforms largest mental health centered communities for nearly two years. Our exploration of mental health discussion will leverage the rich data set provided by the platform in order to explore changes in mental health and addiction discussions in the period leading up to, as well as the beginning of the 2019-2020 pandemic. 

Link to the original study (@Low2020-iu):  
Low , D., Rumker, L., Talkar, T., Torous, J., Cecchi, G., &amp; Ghosh, S. (2020, October 12). Natural language processing reveals vulnerable mental health support groups and heightened health anxiety on reddit during COVID-19: Observational study. Journal of medical Internet research. Retrieved from https://pubmed.ncbi.nlm.nih.gov/32936777/ 

This Dataset was created in conjunction with the National Institutes of Health in order to in to gather a more solid understanding of how online mental health support groups were utilized as a coping mechanism during the beginning of the 2019-2020 Pandemic. According to observational analysis conducted by the World Health Organization, the beginning lockdown period of the COVID-19 Pandemic saw an explosion of Anxiety, Depression, and related disorders (@whoCOVID19Pandemic, 1). The negative effects of this rapidly growing mental crisis were only compounded by what the World Health Organization describes as a "Gap in Care". As a result of spiking costs in healthcare, impacted medical facilities due to COVID-19 infection, and isolation as a result of lockdowns drove many people to seek help and community online as a proxy for face-to-face treatment (@whoCOVID19Pandemic). This trend is especially pronounced in younger populations who have less access to traditional health care.  

In addition to rising rates of mental health disorders, the American Psychological Association noted that substance use disorders grew significantly during the early stages of the Pandemic (@Abramson2021). The CDC estimates that usage rates for non-prescribed drugs increased 13% in time period of June 2019 to June 2020 [@Abramson2021]. This added additional stress to an already fragile healthcare system, and resulted in a spike in overdose related deaths across America in particular, but similar trends were visible world wide.      

Given the wealth of data from the Reddit Mental Health data set Team Tiny Models hopes to analyse the use of the Reddit Platform as tool for connecting those with both mental health disorders and substance use disorders over the years leading up to and immediately proceeding the early 2020 lock downs. As a group, we hope to explore the following questions: 

## Questions

* 1. How did economic stress change over the Pandemic, and did is it related to changes within emotion (i.e. Anger, Anxiety, General Negative Emotion).

* 2. Do changes within substance use disorder communities mirror trends within mental health communities?

* 3. Do different mental health/emotional states affect the number of words written in a post?


## Data

### Data Introduction

The original data in this analysis is from Reddit and comprises 107 different datasets, including posts from 15 mental health support groups across 28 subreddits from 2018 to 2020. It was originally used, from January to April 2020, to analyze how COVID-19 affected mental health support groups[@low2020natural]. The dataset was downloaded from Open Science Framework (OSF)[^1], a free and open-source project management tool for researchers. 

**Reddit Mental Health Dataset**
Contains posts and text features for the following timeframes from 28 mental health and non-mental health subreddits:

* 15 specific mental health support groups (r/EDAnonymous, r/addiction, r/alcoholism, r/adhd, r/anxiety, r/autism, r/bipolarreddit, r/bpd, r/depression, r/healthanxiety, r/lonely, r/ptsd, r/schizophrenia, r/socialanxiety, and r/suicidewatch)  
* 2 broad mental health subreddits (r/mentalhealth, r/COVID19_support)  
* 11 non-mental health subr*eddits (r/conspiracy, r/divorce, r/fitness, r/guns, r/jokes, r/legaladvice, r/meditation, r/parenting, r/personalfinance, r/relationships, r/teaching).

Each group has four datasets. For example the adhd group has the following datasets: adhd_2018_features_tfidf256, adhd_2019_features_tfidf256, adhd_post_features_tfidf256, and adhd_pre_features_tfidf256.

* post: Jan 1 to April 20, 2020 (called "mid-pandemic" in manuscript; r/COVID19_support appears). Unique users: 320,364. 
* pre: Dec 2018 to Dec 2019. A full year which provides more data for a baseline of Reddit * posts. Unique users: 327,289.
* 2019: Jan 1 to April 20, 2019 (r/EDAnonymous appears). A control for seasonal fluctuations to match post data. Unique users: 282,560.
* 2018: Jan 1 to April 20, 2018. A control for seasonal fluctuations to match post data. Unique users: 177,089

Unique users across all time windows (pre and 2019 overlap): 826,961.

**Variables description:**
* subreddit: grupos on Reddit about a topic
* author: unique in the same group
* year
* month
* day
* post
* n_words: number of words in each post
* Sent_neg: the probability of the post being negative (calculate by an algorithm)
* Sent_neu: the probability of the post being neutral (calculate by an algorithm)
* Sent_pos: the probability of the post being positive (calculate by an algorithm)

**Variables that represent mental health issues:**
All variables below represent the number or words detected by the **liwc**[^2] scale that represent that specific sentiment. It is a measured through people's text.

* Isolation_total 
* Domestic_stress_total
* Economic_stress_total
* liwc_anger
* liwc_anxiety
* liwc_negative_emotion
* liwc_positive_emotion
* liwc_sadness	

Stress scale: Individual scores on the Perceived Stress Scale 14 (PSS) can range from 0 to 56, with higher scores indicating higher perceived stress.

**License**
This dataset is made available under the Public Domain Dedication and License v1.0 whose full text can be found at [http://www.opendatacommons.org/licenses/pddl/1.0/](http://www.opendatacommons.org/licenses/pddl/1.0/)

[^1]: [Open Science Framework](https://osf.io/7peyq/l)
[^2]: [LWIC - How it works](https://www.liwc.app/help/howitworks)

### Load packages

```{r load-packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(forcats)
library(olsrr)
library(skimr)
library(viridis)
library(srvyr)
library(scales)
library(osfr) #from osf website
library(zoo)
library(DT)
library(HH)
```

### Data Import

```{r data-import, warning=FALSE}

if(!file.exists("data/mental_health_.rda")) {
  cidr <- getwd()
  mkfldr <- "data/"
  dir.create(file.path(cidr, mkfldr), recursive = TRUE)
  osf_retrieve_file("https://osf.io/7peyq/data/input/5efd0743af1156008d3b5532") |>
    osf_download("data/")
}

```

### Data Wrangling

The original data after importing comprises 107 different datasets, with 350 variables each, in a 2.6GB compress file, but only 56 are useful for our analysis. These 56 datasets are related to the following mental health groups with four datasets each: anxiety, socialanxiety, healthanxiety,  autism, adhd, ptsd, lonely, depression, suicidewatch, bipolarreddit, bpd, addiction, alcoholism, and schizophrenia.

Steps taken to reshape the data that would be useful for our analysis:

#### Step 1

**Get related mental datasets:** select only datasets related to mental health groups mentioned previously. The code below will check if data already exists, if so, it will skip this step.

```{r data-wrangling-step-1, message=FALSE}

if(!file.exists("data/mental_health.rda")) {
  
  # GET RELATED MENTAL FILES
  mental_files = "anxiety|autism|adhd|ptsd|lonely|depression|suicidewatch|bipolarreddit|bpd|addiction|alcoholism|schizophrenia"
  
  data <- list.files(recursive = TRUE,
                     path = "data/reddit_mental_health_dataset",
                     pattern = mental_files,
                     full.names = TRUE) |>
    purrr::map(~read_csv(.))
}
```

#### Step 2

**Combine datasets:** after dataset selection, we combine them all, since they have the same structure.

```{r data-wrangling-step-2}

if(!file.exists("data/mental_health.rda")) {
  
  # COMBINE DATASETS
  red_mh <- data |>
    map_df(bind_rows)

}
```

#### Step 3

**Select important features:** select only the most useful features among 350 originally.

```{r data-wrangling-step-3}

if(!file.exists("data/mental_health.rda")) {
  
  # SELECT IMPORTANT FEATURES FROM DATASET
features <- c("subreddit", "author",	"date", "post", "n_words", "sent_neg", "sent_neu", "sent_pos", "isolation_total", "economic_stress_total", "domestic_stress_total", "liwc_anger", "liwc_anxiety", "liwc_negative_emotion", "liwc_positive_emotion", "liwc_sadness")
  
  red_mh <- red_mh |>
    select(all_of(features))
}
```

#### Step 4

**drop duplication:**  Because two datasets overlap, **pre**: Dec 2018 to Dec 2019, and **2019**: Jan 1 to April 20, 2019, we will drop duplicate data.

```{r data-wrangling-step-4}

if(!file.exists("data/mental_health.rda")) {
  
  # DROP DUPLICATE USER
  red_mh <- unique(red_mh)
}
```

#### Step 5

**Split date:** create three new variables for date: year, month, and day, and drop date.

```{r data-wrangling-step-5}

# IF DATA EXISTS IT WILL SKIP THIS STEP
if(!file.exists("data/mental_health.rda")) {
  
  # SPLIT DATE IN YEAR MONTH AND DAY
  red_mh <- red_mh |>
    separate(date, c("year", "month", "day"), remove = TRUE)
  
}
```

#### Step 6

**Save dataset and delete raw data:** save the non-wrangled and wrangled datasets into the data folder, and delete 51 unnecessary and unused datasets from 107 total, releasing about 2.5GB on disk.

```{r data-wrangling-step-6}

# IF DATA EXISTS IT WILL SKIP THIS STEP
if(!file.exists("data/mental_health.rda")) {
  
  # SAVE THE FINAL DATASET
  save(red_mh, file="data/mental_health.rda")
  
  # DELETE RAW DATA: 107 FILES, +/- 2.5GB
  unlink("data/reddit_mental_health_dataset", recursive = TRUE)
}
```

#### Load the data

```{r load-data}

# LOAD THE DATASET
load("data/mental_health.rda")
```

## Analysis

### Exploratory Data Analysis

**Summary of the data:**
Our data has 390119 rows, and 18 columns, with 6 columns as character, and 12 as numeric. Any missing value detected across variables. The summary of some variables doesn't see right at first glance; for instance, the subreddit variable has **min 3** and **max 13**, but because they are character, so the summary shows the length of each category under that variable. The mean of the variables thatrepresent mental health issues are significant and we will explore them through the analysis.

```{r eda}
skim(red_mh)
```
#### Subreddit groups:

Number os subreddit groups during Dec 2018 to Apr 2020. Here we can see that some groups have a great amount of poster, such as adhd, anxiety, bpd, depression, lonely, socialanxiety, and suicidewatch.

```{r}
table(red_mh$subreddit)
```

#### Total number of emotional words:
Below we summarized the total of all sentiment variables detected by LIWC by year, only for obersevation purpose.

```{r}

datatable(red_mh |>
  group_by(year) |>
  summarise(
    total_isolation = sum(isolation_total),
    total_economic_stress = sum(economic_stress_total),
    total_domestic_stress = sum(domestic_stress_total),
    total_anger = sum(liwc_anger),
    total_anxiety = sum(liwc_anxiety),
    total_neg_emotion = sum(liwc_negative_emotion),
    total_pos_emotion = sum(liwc_positive_emotion),
    total_sad_emotion = sum(liwc_sadness)
  ))
```


#### Sum of the number of posts' words across the data:

The graph below show the total number of words in each post by year. It adds on with out table above. Although they might not be related.

```{r eda-1}

options(scipen = 999)
red_mh |>
  group_by(year) |>
  summarize(total_words = sum(n_words)) |>
  ggplot(aes(y = total_words,
             x = year, fill=year)) +
  geom_bar(stat = "identity",
           # position = "dodge"
           ) +
  scale_fill_viridis(discrete = TRUE, option="cividis") + 
  theme_minimal() +
  guides(fill = guide_legend("Flavor")) +
  labs(title = "Number of words present in all subreddit groups from Dec 2018 to Apr 2020",
       subtitle = "Number in millions",
       x = NULL,
       y =NULL) + 
  guides(fill = "none") +
  theme(
    plot.title.position = "plot",
    axis.text.x=element_text(size=12),
    axis.text.y=element_text(size=12),
    panel.grid.major.x = element_blank()
  ) +
 scale_y_continuous(labels = scales::label_number_si())
```

The graph below shows the total number of words only for 2019 and 2020 from Jan to Apr, since for 2018 we only have Dec with data. 2020 overpass 2019 slightly

```{r eda-2}

options(scipen = 999)
red_mh |>
  filter(
    month == "01" | month == "02" | month == "03"  | month == "04",
    year == "2019" | year == "2020"
  ) |>
  group_by(year) |>
  summarize(total_words = sum(n_words)) |>
  ggplot(aes(y = total_words,
             x = year, fill = year)) +
  geom_bar(stat = "identity",
           # position = "dodge"
  ) +
  scale_fill_manual(values = c("2020" = "#ef8a62")) +
  theme_minimal() +
  guides(fill = guide_legend("Flavor")) +
   labs(title = "Number of words present in all subreddit groups in 2019 and 2020 from Jan to Apr",
       subtitle = "Number in millions",
       x = NULL,
       y =NULL) + 
  guides(fill = "none") +
  scale_y_continuous(labels = scales::label_number_si())
```

#### carlos

The graph below show the total of emotional words by emotion detected by LIWC by year.

```{r eda-2}

options(scipen = 999)
red_mh |>
  group_by(year) |>
  summarize(
    isolation_total = sum(isolation_total),
    economic_stress_total = sum(economic_stress_total),
    domestic_stress_total = sum(domestic_stress_total),
    liwc_anger = sum(liwc_anger),
    liwc_anxiety = sum(liwc_anxiety),
    liwc_negative_emotion = sum(liwc_negative_emotion),
    liwc_positive_emotion = sum(liwc_positive_emotion),
    liwc_sadness = sum(liwc_sadness),
            ) |>
  pivot_longer(isolation_total:liwc_sadness,
               names_to = "emotion",
               values_to = "tot_emot_words") |>
  mutate(emotion =fct_reorder(emotion,tot_emot_words)) |>
  ggplot(aes(y=emotion,
             x = tot_emot_words,
             fill=emotion)) +
  geom_bar(stat = "identity",position = "dodge") +
  scale_fill_viridis(discrete = TRUE, option="cividis") +
  facet_wrap(~year, nrow = 1) +
  guides(fill = "none") +
  labs(title="Total of emotional words detected by LIWC from Dec 2018 to Apr 2020",
       # subtitle="subtitle",
       x=NULL,
       y=NULL
  ) +
  theme(
    plot.title.position = "plot",
    axis.text.x=element_text(size=8),
    axis.text.y=element_text(size=8)
  ) +   scale_x_continuous(labels = scales::label_number_si())
```

#### carlos

The graph below shows the same information of the graph above, but only for 2019 and 2020.

```{r eda-3}

# total of emotional words by emotions detected by liwc jan-apr 2019-2020 (TABLE AND plot)

red_mh |>
  filter(
    month == "01" | month == "02" | month == "03"  | month == "04",
    year == "2019" | year == "2020"
  ) |>
  group_by(year) |>
  summarize(
    isolation_total = sum(isolation_total),
    economic_stress_total = sum(economic_stress_total),
    domestic_stress_total = sum(domestic_stress_total),
    liwc_anger = sum(liwc_anger),
    liwc_anxiety = sum(liwc_anxiety),
    liwc_negative_emotion = sum(liwc_negative_emotion),
    liwc_positive_emotion = sum(liwc_positive_emotion),
    liwc_sadness = sum(liwc_sadness)
    ) |>
    pivot_longer(isolation_total:liwc_sadness,
                 names_to = "emotion",
                 values_to = "total_emot_words")

options(scipen = 999)
red_mh |>
  filter(
    month == "01" | month == "02" | month == "03"  | month == "04",
    year == "2019" | year == "2020"
  ) |>
  group_by(year) |>
  summarize(
    isolation_total = sum(isolation_total),
    economic_stress_total = sum(economic_stress_total),
    domestic_stress_total = sum(domestic_stress_total),
    liwc_anger = sum(liwc_anger),
    liwc_anxiety = sum(liwc_anxiety),
    liwc_negative_emotion = sum(liwc_negative_emotion),
    liwc_positive_emotion = sum(liwc_positive_emotion),
    liwc_sadness = sum(liwc_sadness)
    ) |>
    pivot_longer(isolation_total:liwc_sadness,
                 names_to = "emotion",
                 values_to = "total_emot_words") |>
    mutate(emotion =fct_reorder(emotion,total_emot_words)) |>
    ggplot(aes(y=emotion,
               x = total_emot_words,
               fill=emotion)) +
    geom_bar(stat = "identity",position = "dodge") +
    scale_fill_viridis(discrete = TRUE, option="cividis") +
    facet_wrap(~year, nrow = 1) +
    guides(fill = "none") +
    labs(title="Total of emotional words detected by LIWC from Jan to Apr of 2019 and 2020",
         # subtitle="subtitle",
         x=NULL,
         y=NULL
    ) +
    theme(
      plot.title.position = "plot",
      panel.spacing = unit(1, "cm"),
      axis.text.x=element_text(size=5),
      axis.text.y=element_text(size=7)
    ) +   scale_x_continuous(expand = c(0, 0), limits = c(0,700000), n.breaks = 6,
                             labels = scales::label_number_si())


```

#### carlos

<!-- # percentage of liwc per subreddit per year -->
The next graph shows the percentage of each sentiment per subreddit from Jan to Apr of 2019 and 2020. We see a few sentiments that had a significant increase, such as suicidewatch group.

```{r eda-5, message=FALSE}

# percentage of liwc per subreddit per year
options(scipen = 999)
red_mh |>
  filter(
    year!="2018", 
    month=="01" | month=="02" | month=="03" | month=="04") |>
  group_by(subreddit, year) |>
  summarize(
    n_words = (mean(n_words) * 100),
    isolation_total = (mean(isolation_total) * 100),
    economic_stress_total = (mean(economic_stress_total) * 100),
    domestic_stress_total = (mean(domestic_stress_total) * 100),
    liwc_anger = (mean(liwc_anger) * 100),
    liwc_anxiety = (mean(liwc_anxiety) * 100),
    liwc_negative_emotion = (mean(liwc_negative_emotion) * 100),
    liwc_positive_emotion = (mean(liwc_positive_emotion) * 100),
    liwc_sadness = (mean(liwc_sadness) * 100)
  ) |>
  pivot_longer(isolation_total:liwc_sadness,
               names_to = "emotion",
               values_to = "perc_emotion") |>
  # summarise(a=n_words, b=)
  mutate(emotion =fct_reorder(emotion,perc_emotion)) |>
  ggplot(aes(y=emotion,
             x = perc_emotion,
             fill=year)) +
  geom_bar(stat = "identity",position = "dodge") +
  scale_x_continuous(labels = scales::percent_format(scale=.1)) +
  # scale_fill_viridis(discrete = TRUE, option="cividis") +
  facet_wrap(~subreddit, nrow = 3) +
  guides(fill = "none") +
  labs(title="Percentage of sentiment captured in each subreddit group",
       subtitle="From Jan to Apr of 2019 and 2020.",
       x=NULL,
       y=NULL
  ) +
  theme(
    plot.title.position = "plot",
     # panel.spacing = unit(1, "cm"),
    axis.text.x=element_text(size=6),
    axis.text.y=element_text(size=6)
  ) 

```

The table below informs us the average of number of words in each post, as well as the average of each sentiment in that post grouped by subreddit group and year.

```{r eda-6, message=FALSE}

datatable(red_mh |>
  filter(year!="2018",
         month=="01" | month=="02" | month=="03" | month=="04"
  ) |>
  rowwise() |>
  mutate(total_w=sum(c(isolation_total, economic_stress_total, domestic_stress_total,liwc_anger,liwc_anxiety, liwc_negative_emotion, liwc_positive_emotion, liwc_sadness))) |>
  ungroup() |>
  group_by(subreddit, year) |>
  summarize(
    avg_num_words_post = (mean(n_words)),
    avg_sent_words_post = (mean(total_w))
  ))
```

Based on the two graphs below, we see that there is an relationship between the number of emotional words found in a post and the lengths of it.

```{r eda-7, message=FALSE}

df_2018<-red_mh |>
  filter(year=="2018") |>
  rowwise() |>
  mutate(total_w=sum(c(isolation_total, economic_stress_total, domestic_stress_total,liwc_anger,liwc_anxiety, liwc_negative_emotion, liwc_positive_emotion, liwc_sadness))) |>
  ungroup() |>
  group_by(month) |>
  summarize(
    n_words = (mean(n_words)),
    sent_w = (mean(total_w))
  ) 

df_2019<-red_mh |>
  filter(year=="2019") |>
  rowwise() |>
  mutate(total_w=sum(c(isolation_total, economic_stress_total, domestic_stress_total,liwc_anger,liwc_anxiety, liwc_negative_emotion, liwc_positive_emotion, liwc_sadness))) |>
  ungroup() |>
  group_by(month) |>
  summarize(
    n_words = (mean(n_words)),
    sent_w = (mean(total_w))
  ) 

df_2020<-red_mh |>
  filter(year=="2020") |>
  rowwise() |>
  mutate(total_w=sum(c(isolation_total, economic_stress_total, domestic_stress_total,liwc_anger,liwc_anxiety, liwc_negative_emotion, liwc_positive_emotion, liwc_sadness))) |>
  ungroup() |>
  group_by(month) |>
  summarize(
    n_words = (mean(n_words)),
    sent_w = (mean(total_w))
  ) 

data <- rbind(df_2018, df_2019, df_2020)

   ggplot(data, aes(x = sent_w,y=n_words)) +
  geom_point() +
     geom_smooth(method="lm") + 
     labs(title="Relation of number of emotional words by LWIC and post's length",
       subtitle="From 2018 to 2020",
       x="Average of words in a post",
       y="Average of emotional words"
  ) +
   scale_y_continuous(labels = scales::label_number_si())
   
  ggplot(data, aes(x = sent_w,y=n_words)) +
    geom_line() +
     labs(title="Relation of number of emotional words by LWIC and post's length",
       subtitle="From 2018 to 2020",
       x="Average of words in a post",
       y="Average of emotional words"
  ) +
   scale_y_continuous(labels = scales::label_number_si())
```

## Data Analysis

### Question 1:

Given the LIWC data which contains scientific research to backup a language that someone uses can be used to identify their emotional, anxious, happy state, etc. (https://www.liwc.app/help/howitworks) Here the the economic stress is seen how it changes through 2018 to 2020. We can see it is the highest stressor and for the emotions associated with it we can see anxiety is the highest emotion related with economic stress. This is expected since the economy during COVID hit many countries around the world hard especially the supply chain and having a everlasting effect on the demand and financial sides (https://www.brookings.edu/research/ten-facts-about-covid-19-and-the-u-s-economy/).

```{r message=FALSE}
red_mh |>
  group_by(subreddit, year) |>
  summarize(Negative = (mean(sent_neg) * 100),
            Neutral = (mean(sent_neu) * 100),
            Positive = (mean(sent_pos) * 100)) |>
  pivot_longer(cols = -subreddit & -year, 
               names_to = "sentiment",
               values_to = "Percentage of subredditors") |>            
  ggplot(aes(x = year, y= `Percentage of subredditors` , fill = (sentiment))) +
  geom_bar(stat = "identity",
           position = "dodge",
           color = "black") +
  scale_y_continuous(expand = c(0, .3)) +
  coord_flip() +
  facet_wrap(~ subreddit, nrow=3) +
  guides(fill = guide_legend("sentiment")) +
  labs(title = "Sentiment of redditors by subreddit",
       subtitle = "Neutral appear to be used the most frequently") + theme(text = element_text(size = 15)) + 
  theme(
    plot.title = element_text(size = 15, face = "bold"),
    axis.title.x = element_blank(),

    axis.text.x = element_blank(),
    axis.ticks.x=element_blank(),
    axis.title.y = element_blank()
    )
```

```{r}
red_mh |>
  group_by(year) |>
  summarize(Negative = (mean(sent_neg) * 100),
            Neutral = (mean(sent_neu) * 100),
            Positive = (mean(sent_pos) * 100)) |>
  pivot_longer(cols = -year, 
               names_to = "sentiment",
               values_to = "Percentage of subredditors") |>            
  ggplot(aes(x = year, y= `Percentage of subredditors` , fill = sentiment)) +
  geom_bar(stat = "identity",
           position = "dodge",
           color = "black") +
  scale_y_continuous(expand = c(0, .3)) +
  coord_flip() +
  guides(fill = guide_legend("sentiment")) +
  labs(title = "Sentiment of redditors by subreddit",
       subtitle = "Neutral appear to be used the most frequently") + theme(text = element_text(size = 15)) + 
  theme(
    plot.title = element_text(size = 15, face = "bold"),
    axis.title.x = element_blank(),

    axis.text.x = element_blank(),
    axis.ticks.x=element_blank(),
    axis.title.y = element_blank()
    )
```

Seen how a 'negative' sentiment is common across the subreddits after neutral we want to see other variables and see if there are some patterns like more economic stress can be a factor of this. As seen from the bar plot the economic stress throughout the pandemic decreased slightly. In 2018 the economic stress is high as the average is > 80 % and in 2019 this drops to < 80 % and drops further in 2020. Nonetheless, this is still the highest compared to domestic and isolation.

```{r}
red_mh |>
  group_by(year) |>
  summarize(Isolation = mean(isolation_total),
            Economic = mean(economic_stress_total),
            Domestic = mean(domestic_stress_total)) |>
  pivot_longer(cols = -year, 
               names_to = "Type",
               values_to = "Percentage") |>
  rename(Year = year) |>
  ggplot(aes(y = Percentage,
             x = Year,
             fill = reorder(Type, Percentage))) +
  geom_bar(stat = "identity",
           position = "dodge",
           color = "black") +
  theme_linedraw() +
  guides(fill = guide_legend("Stressors")) +
  labs(title = "Sentiment of redditors by year",
       subtitle = "Economic appear to be the most frequently") + theme(text = element_text(size = 15)) + 
  theme(
    plot.title = element_text(size = 15, face = "bold"))
```

### Question 2

In order to explore the relationship between substance abuse community data and the WHO's inference that these communities be driven online. If this inference were to be true, we should see that regardless of sentiment, there should in theory be more and longer posts to the substance abuse communities. This would represent an increases in community engagement. Because there are gaps in the data, we will be limiting the exploration the time period of January to April for both 2019 and 2020. This represents the very beginnings of the Pandemic Lockdowns where we would expect to see changes.

In order to look into the activity on addiction related subreddits, it makes sense to analyse the frequency and length of new posts to the individual subreddits. As there is a time gap within the data we have selected to analyse the January to June period of both 2019 and 2020 and compare the two. I decided to smoothe the graphic to a 7 day rolling average in order to reduce some noise.

```{r question-4, warning=FALSE}
#Unify the date object to make analysis easier.
red_mh$Date <- as.Date(with(red_mh, paste(year, month, day,sep="-")), "%Y-%m-%d")

#Filter the data for the addiction related subreddits
post_data <- red_mh[red_mh$subreddit %in% c('addiction','alcoholism'),] |>
  drop_na(Date)

#Identify the time window
post_data2020 <- post_data[(post_data$Date >= as.Date("2020-01-01")) & (post_data$Date <= as.Date("2020-04-01")),]
post_data2019 <- post_data[(post_data$Date >= as.Date("2019-01-01")) & (post_data$Date <= as.Date("2019-04-01")),]

#Generate a chart of the Date and subreddit data charting the amount of posts per dat
post_data2020 |>
  group_by(Date, subreddit) %>%
  summarise(total_count=n(),.groups = 'drop') |>
  ggplot(aes(x=Date, y=total_count, group=subreddit, color=subreddit)) +
  geom_line(aes(y=rollmean(total_count, 7, na.pad=TRUE))) +
  geom_line(aes(y = mean(total_count)), color="darkred") +
  #geom_hline(yintercept = mean(total_count), color="blue") +
  xlab("Date") +
  ylab("Posts per Day (Count)") +
  labs(title = "Posts per Day on Addiction Related Subreddits Jan-Apr 2020")

post_data2019 |>
  group_by(Date, subreddit) %>%
  summarise(total_count=n(),.groups = 'drop') |>
  ggplot(aes(x=Date, y=total_count, group=subreddit, color=subreddit)) +
  geom_line(aes(y=rollmean(total_count, 7, na.pad=TRUE))) +
  geom_line(aes(y = mean(total_count)), color="darkred") +
  #geom_hline(yintercept = mean(total_count), color="red") +
  xlab("Date") +
  ylab("Posts per Day (Count)") +
  labs(title = "Posts per Day on Addiction Related Subreddits Jan-Apr 2019")

```

Given the charts above, we see that there was increased usage of the addiction and alcoholism communities. We saw on average ~1 post more than in the same period than the year before. In order to gauge engagement we should next check to see if the post length changed. Shorter but more frequent posts may indicate that post-frequency may indicate spam or or other artificial growth of the data.
Plotting the data

```{r}

post_data2020 |>
  group_by(Date) |>
  summarise(mean_count = mean(n_words)) |>
  ggplot(aes(x = Date, y = mean_count)) +
  geom_col(position = 'dodge') +
  geom_line(aes(y = mean(mean_count)), color="darkred") +

  #Fix up the format so that it is legible
  xlab("Date") +
  ylab("Length of Post (words)") +
  labs(title = "The Length of Addiction Related Posts over Time Jan-Apr 2020")

post_data2019 |>
  group_by(Date) |>
  summarise(mean_count = mean(n_words)) |>
  ggplot(aes(x = Date, y = mean_count)) +
  geom_col(position = 'dodge') +
  geom_line(aes(y = mean(mean_count)), color="darkred") +

  #Fix up the format so that it is legible
  xlab("Date") +
  ylab("Mean Length of Posts (words)") +
  labs(title = "The Length of Addiction Related Posts over Time Jan-Apr 2019")
```

Now that we can infer that posts within addiction related subreddits were both more frequent and were as long as posts from the same period the prior year. From this we can infer that during the early months of 2020 there was more global engagement than in the same period of 2019.

```{r}
post_data2020 |>
  group_by(Date) %>%
  summarise(mean_pos = mean(sent_pos),
            mean_neu = mean(sent_neu),
            mean_neg= mean(sent_neg),
            .groups = 'drop') |>
  ggplot(aes(x=Date)) +
  geom_line(aes(y = mean_pos, color = "Positive Sentiment")) +
  geom_line(aes(y = mean_neu, color = "Neutral Sentiment")) +
  geom_line(aes(y = mean_neg, color = "Negative Sentiment")) +
  scale_color_manual(name = "Y series", values = c("Positive Sentiment" = "darkred", "Neutral Sentiment" = "blue", "Negative Sentiment" = "green"))+
  xlab("Date") +
  ylab("Sentiment Proportion") +
  labs(title = "Mean sentiment accross posts for JAN-APR 2019")

post_data2019 |>
  group_by(Date) %>%
  summarise(mean_pos = mean(sent_pos),
            mean_neu = mean(sent_neu),
            mean_neg= mean(sent_neg),
            .groups = 'drop') |>
  ggplot(aes(x=Date)) +
  geom_line(aes(y = mean_pos, color = "Positive Sentiment")) +
  geom_line(aes(y = mean_neu, color = "Neutral Sentiment")) +
  geom_line(aes(y = mean_neg, color = "Negative Sentiment")) +
  scale_color_manual(name = "Y series", values = c("Positive Sentiment" = "darkred", "Neutral Sentiment" = "blue", "Negative Sentiment" = "green"))+
  xlab("Date") +
  ylab("Sentiment Proportion") +
  labs(title = "Mean sentiment accross posts for JAN-APR 2020") +
  theme(
    plot.title.position = "plot"
  ) 

```

## Modeling

#### Modeling Question 1

Taking a look at multicolinearity a model is fit to see what changes like sentiment of negativity, positivity detected, etc. leads to multicolinearity. This model tells which variables to eliminate based on a high VIF which tells us variance of an estimated regression coefficient using colinearity. The point of this is to eliminate independent variables from affecting our linear regression. 

```{r}
lm<- linear_reg() |>
  set_engine("lm") |>
  fit(economic_stress_total ~ 
        sent_neg +
        sent_neu +
        sent_pos +
        liwc_anger +
        liwc_anxiety +
        liwc_negative_emotion +
        liwc_positive_emotion +
        liwc_sadness,
      data = red_mh)
tidy(lm)
```
```{r}
lm2 <- lm(economic_stress_total ~ 
        sent_neg +
        sent_neu +
        sent_pos +
        liwc_anger +
        liwc_anxiety +
        liwc_negative_emotion +
        liwc_positive_emotion +
        liwc_sadness,
      data = red_mh)
summary(lm2)
```

```{r}
vif_red <- vif(lm2)
vif_red
```

On average we can see for an increase in anger detected the economic stress is increased by .11, an increased in anxiety is an increase of .02 in economic stress, an increase in positive emotio is an increase of .07 for economic stress and an increase in sadness is an increase of .09 for economic stress.

```{r}
lm3 <- lm(economic_stress_total ~ 
        liwc_anger +
        liwc_anxiety +
        liwc_positive_emotion +
        liwc_sadness,
      data = red_mh)
summary(lm3)
vif_red2 <- vif(lm3)
vif_red2
```


Using a backword apporach which is a different model  to see which variables doesn't add predictive power we can see Sent_neu doesn't add any predictive power since it has a high adjusted R-squared value. Still we'll eliminate the independent variables to get as much of a accurate linear model

```{r}
# fit the model (not using tidymodels)
mod <- lm(economic_stress_total ~ sent_neg +
        sent_neu +
        sent_pos +
        liwc_anger +
        liwc_anxiety +
        liwc_negative_emotion +
        liwc_positive_emotion +
        liwc_sadness,
      data = red_mh)
ols_step_backward_p(mod)
```

Using the interactive linear model we can see that anxiety is the greatest predictor for economic stress: economic stress = .06 * sadness + .07 * anxiety + .01 * sadness + .07 * positive emotion. In order to visualize this a linear plot is used to show how an increase in LIWC of either of the variables is associated to an increase in economic stress.

```{r}
lin_mod <- linear_reg() |>
  set_engine("lm")

pp_int_fit <- lin_mod |>
  fit(economic_stress_total ~ liwc_sadness * liwc_anxiety * liwc_anger * liwc_positive_emotion, data = red_mh)
tidy(pp_int_fit)

red_mh |>
  ggplot(aes(x = economic_stress_total, y = liwc_sadness)) +
  geom_point()+
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "economic stress and liwc sadness",
       subtitle = "Economic appear to be associated with detection of sadness", color = "landscape") 

red_mh |>
  ggplot(aes(x = economic_stress_total, y = liwc_anxiety)) +
  geom_point()+
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "economic stress and liwc anxiety",
       subtitle = "Economic appear to be associated with detection of anxiety", color = "landscape")
red_mh |>
  ggplot(aes(x = economic_stress_total, y = liwc_anger)) +
  geom_point()+
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "economic stress and liwc anger",
       subtitle = "Economic appear to be associated with detection of anger", color = "landscape")
red_mh |>
  ggplot(aes(x = economic_stress_total, y = liwc_positive_emotion)) +
  geom_point()+
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "economic stress and liwc sadness",
       subtitle = "Economic appear to be associated with detection of positive emotion", color = "landscape")
```

#### Modeling Question 2

When looking at the average sentiment across posts for each day, there doesn't seem to be much of a change between the JAN-APR 2019 and JAN-APR of 2020 time periods.

Analysing the negative sentiment data from the substance abuse communities, we decided to focus on what contributed to a

```{r}
use_senti2019 <- lm(sent_neg ~ n_words +
                            sent_neu +
                            sent_pos +
                            liwc_anger +
                            liwc_anxiety +
                            liwc_negative_emotion +
                            liwc_positive_emotion +
                            liwc_sadness +
                            economic_stress_total +
                            isolation_total +
                            domestic_stress_total, data = post_data2019)

glance(use_senti2019)
use_senti2019


use_senti2020 <- lm(sent_neg ~ n_words +
                            sent_neu +
                            sent_pos +
                            liwc_anger +
                            liwc_anxiety +
                            liwc_negative_emotion +
                            liwc_positive_emotion +
                            liwc_sadness +
                            economic_stress_total +
                            isolation_total +
                            domestic_stress_total, data = post_data2020)

glance(use_senti2020)
use_senti2020
```

Accounting for the two separate years, a similar model used between the two time periods explain significantly different amounts of variation. The posts from the 2019 time period were much more correlated with the other data. The Pandemic likely served as a significant confound.

Another interesting idea of the substance abuse subreddits is the idea that negative or positive posts generally influencing the length of post.

```{r}
len_predict2019 <- lm(n_words ~ sent_neg +
                            sent_neu +
                            sent_pos +
                            liwc_anger +
                            liwc_anxiety +
                            liwc_negative_emotion +
                            liwc_positive_emotion +
                            liwc_sadness +
                            economic_stress_total +
                            isolation_total +
                            domestic_stress_total, data = post_data2020)

ols_step_backward_p(len_predict2019)
glance(len_predict2019)
len_predict2019


len_predict2020 <- lm(n_words ~ sent_neg +
                            sent_neu +
                            sent_pos +
                            liwc_anger +
                            liwc_anxiety +
                            liwc_negative_emotion +
                            liwc_positive_emotion +
                            liwc_sadness +
                            economic_stress_total +
                            isolation_total +
                            domestic_stress_total, data = post_data2020)

ols_step_backward_p(len_predict2020)
ols_step_backward_p(len_predict2020)

glance(len_predict2020)
len_predict2020
```

Interestingly the length of substance abuse related posting is strongly explained by the emotional content of the posting itself. Each model is sitting at ~82% of total variation explained. Posts that are sadder and angrier are shorter, while those that exhibit more general negative emotions or happiness tend to be longer in length. The ols step back methhod indicated thatt the sent_pos was cut, this makes sense as it should generally just be the inverse of the sent_neg and not providing eficacy to the model.

All in all the Substance Abuse Data shows that communities centered around communal aide and coping with use disorders grew and were generally more active during the 2020 Pandemic than they were in the similar time window for 2019. That said, there were little sentiment changes between the two time windows, and what the make up of posts was relatively consistent.

#### Modeling Question 3

The model below is compatible with our findings before, about the relationship of number of emotional words found in each post and it lengths.

```{r}

mod_all_sent_2020 <- lm(n_words ~
                 isolation_total +
                 economic_stress_total +
                 domestic_stress_total +
                 liwc_anger +
                 liwc_anxiety +
                 liwc_negative_emotion +
                 liwc_positive_emotion +
                 liwc_sadness,
               data = red_mh)

ols_step_backward_p(mod_all_sent_2020)

glance(mod_all_sent_2020)

tidy(mod_all_sent_2020)
```

## Conclusion

**How did economic stress change over the Pandemic, and did is it related to changes within emotion (i.e. Anger, Anxiety, General Negative Emotion).**
We can see that economic stress is the highest contributor of stress in the posts and stayed relatively high as the years progressed. Through a multiple linear regression model we were able to see how detectors of sadness, anxiety, anger and positive emotion are able to predict a post involving economic stress.

**Do changes within substance use disorder communities mirror trends within mental health communities?**
All in all the Substance Abuse Data shows that communities centered around communal aide and coping with use disorders grew and were generally more active during the 2020 Pandemic than they were in the similar time window for 2019. That said, there were little sentiment changes between the two time windows, and what the make up of posts was relatively consistent.

**Do different mental health/emotional states affect the number of words written in a post?**
To find the relationship between word count and mental health/emotional states, we conducted a multiple linear regression. We found that predicted that neutral posts, economic stress, domestic stress, negative emotion, and positive emotion generally increase wordiness. Anger, anxiety, and sadness increase wordness.
